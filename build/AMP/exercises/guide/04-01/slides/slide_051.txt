we're going to explore how different file types interact with Apache Iceberg, particularly focusing on Parquet and ORC formats. Understanding these file types is crucial for optimizing your data storage and retrieval processes in a distributed environment like Iceberg.

1. **Default File Type - Parquet**:
   - Parquet is a columnar storage file format optimized for use with big data processing frameworks.
   - It is the default file type for many big data applications, including Iceberg.
   - Parquet is highly efficient for read-heavy operations and supports advanced features like predicate pushdown and efficient compression.

2. **ORC File Type**:
   - ORC (Optimized Row Columnar) is another columnar storage format designed for Hadoop workloads.
   - While Parquet is the default, you can also use ORC with Iceberg by specifying the file format explicitly.
   - To use ORC, you need to set the configuration: `'write.format.default'='orc'`.
   - This is particularly useful if your existing data pipelines or ecosystem are optimized for ORC.

When working with Iceberg, choosing the right file type can significantly impact performance. Parquet is generally preferred for its widespread support and efficiency, but ORC can be a good alternative depending on your specific use case and existing infrastructure.

