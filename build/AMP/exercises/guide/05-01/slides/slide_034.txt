High-Level Workflow Overview
"This diagram represents the operational flow of machine learning models within Cloudera Machine Learning (CML) or Cloudera Data Science Workbench (CDSW)."
At the center, we have the Model Metrics Store, which acts as a central repository for tracking model performance.
Models, represented here, are running as replicas to ensure availability and scalability.
Each model replica handles requests and returns predictions, which are logged for monitoring and evaluation.
Tracking Model Metrics
"To ensure reliable model performance, we need to track various metrics at different stages."
track_metric: Captures key real-time metrics from deployed models.
track_delayed_metric & track_aggregate_metrics: Allow tracking of batch metrics and aggregations over time.
read_metrics: Retrieves stored metrics for analysis and monitoring.
Model Interaction with Business Systems
"Models in production interact with business systems via a request-response mechanism."
Business systems send a Model Request containing input features.
The model processes the request and returns a Model Response with predictions.
These interactions are essential for integrating AI-powered decisions into real-world applications.
Operational Visibility through CML UI
"CML provides a unified interface for different stakeholders."
Data scientists can monitor model performance and track historical metrics through the CML UI.
Operations teams can track model health and system performance using the same interface.
Model Performance Tracking Example
"On the right side of the slide, we have a table displaying recorded metrics."
Columns like met_1 and met_2 track input feature values.
pred and actual allow comparison of model predictions against ground truth labels.
The final accuracy metric, .67, indicates the model's current performance based on recent predictions.
	
